---
title: "TP2 - CART"
author: "Ismael Marchesini - Juan Emmanuel Pengue"
date: "2023-12-12"
output:
  md_document:
    toc: true
    toc_depth: 5
  html_document:
    toc: true
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
library(rpart)
library(rpart.plot)
library(tidyverse)
```

## Sobre los datos: 

El Inventario de Depresión Ansiedad y Estrés (Depression Anxiety and Stress Scale - DASS) es un set the 3 escalas auto-administrables diseñadas para medir los estados emocionales negativos de depresión, ansiedad y estrés. Cada escala individual consta de 14 items, siendo un total de 42 para todo el cuestionario. A su vez, cada escala está dividida en sub-escalas de 2 a 5 items de contenido similar. (... continuar texto https://www2.psy.unsw.edu.au/dass/over.htm)

### Cargamos Datos:

```{r pressure, echo=FALSE}
df <- read.csv('C:/Users/Administrator/Documents/MaestriaDataMining/EEA/TP2/data.csv', header = TRUE, sep="\t")
head(df)
```

### Sobre el tratamiento de los datos: 

Para nuestro caso de estudio, nos interesa el scoring total en cada escala (Depresión, Ansiedad y Estrés respectivamente). Si bien los autores plantean que no son independientes, sino que están hasta cierto punto correlacionadas, vamos a evaluar el grado de severidad para cada caso. Dado que nuestro dataset contiene el score individual marcado para cada pregunta, calcularemos tres columnas adicionales con el score total de cada estado respectivamente. Asimismo, como en este caso los valores van de 1 a 4, y en el DASS original se puntuan de 0 a 3, vamos a restar 1 a todos los valores. 

``` {r Tratamiento de Datos}

#Creamos las columnas que nos interesan

columnas_respuesta <- c("Q1A", "Q2A", "Q3A", "Q4A", "Q5A", "Q6A", "Q7A", "Q8A", "Q9A", "Q10A", "Q11A", "Q12A", "Q13A", "Q14A", "Q15A", "Q16A", "Q17A", "Q18A", "Q19A", "Q20A", "Q21A", "Q22A", "Q23A", "Q24A", "Q25A", "Q26A", "Q27A", "Q28A", "Q29A", "Q30A", "Q31A", "Q32A", "Q33A", "Q34A", "Q35A", "Q36A", "Q37A", "Q38A", "Q39A", "Q40A", "Q41A", "Q42A")

# Restar 1 a las 42 columnas al mismo tiempo
df[, columnas_respuesta] <- df[, columnas_respuesta] - 1

```

```{r Sumamos columnas}


df$Ansiedad <- rowSums(df[, c("Q2A", "Q4A", "Q7A", "Q9A", "Q15A", "Q19A", "Q20A", "Q23A", "Q25A", "Q28A", "Q30A", "Q36A", "Q40A", "Q41A")])
df$Depresion <- rowSums(df[, c("Q3A", "Q5A", "Q10A", "Q13A", "Q16A", "Q17A", "Q21A", "Q24A", "Q26A", "Q31A", "Q34A", "Q37A", "Q38A", "Q42A")])
df$Stress <- rowSums(df[, c("Q1A", "Q6A", "Q8A", "Q11A", "Q12A", "Q14A", "Q18A", "Q22A", "Q27A", "Q29A", "Q32A", "Q33A", "Q35A", "Q39A")])


#Sabemos ademas que el valor máximo de cada escala es 3 para cada pregunta, y son 14 preguntas, en total 42 puntos es el valor maximo en cada escala. 

#Calculamos entonces la proporcion sobre el total maximo

df$Ansiedad_perc <- df$Ansiedad / 42
df$Depresion_perc <- df$Depresion / 42
df$Stress_perc <- df$Stress / 42

head(df[, c("Ansiedad", "Ansiedad_perc", "Depresion", "Depresion_perc", "Stress", "Stress_perc")])

```

También vamos a construir 4 categorias de Severidad para cada Target. 
Depresion: 0-9 normal, 10-13 leve, 14-20 moderado, 21-42 severo
Ansiedad: 0-7 normal, 8-9 leve, 10-14 moderado, 15-42 severo
Stress: 0-14 normal, 15-18 leve, 19-25 moderado, 26-42 severo

Información tomada de la hoja de información de DASS: https://static1.squarespace.com/static/5934abbb1b631ba4718d4c2d/t/604d2386f36aae7a6f01fb67/1615668113669/DASS+23+Information+Sheet.2.25.21.docx.pdf

```{r Construimos categoricas}

df <- df %>%
  mutate(
    Depresion_cat = case_when(
      between(Depresion, 0, 9) ~ "Normal",
      between(Depresion, 10, 13) ~ "Leve",
      between(Depresion, 14, 20) ~ "Moderado",
      between(Depresion, 21, 42) ~ "Severo",
      TRUE ~ NA_character_
    ),
    Ansiedad_cat = case_when(
      between(Ansiedad, 0, 7) ~ "Normal",
      between(Ansiedad, 8, 9) ~ "Leve",
      between(Ansiedad, 10, 14) ~ "Moderado",
      between(Ansiedad, 15, 42) ~ "Severo",
      TRUE ~ NA_character_
    ),
    Stress_cat = case_when(
      between(Stress, 0, 14) ~ "Normal",
      between(Stress, 15, 18) ~ "Leve",
      between(Stress, 19, 25) ~ "Moderado",
      between(Stress, 26, 42) ~ "Severo",
      TRUE ~ NA_character_
    )
)

```


Además de esto, contamos con la escala de Ten Item Personality Inventory, que contiene 10 preguntas que se responden con números del 1 al 7. En base al manual de dicho inventario, debemos recodificar algunas respuestas de la siguiente manera: 

Para los items 2, 4, 6, 8 y 10, codificar a la inversa: 7 como 1, 6 como 2, 5 como 3, etc. 

```{r Recodificando}

# Columnas a codificar
columnas_a_codificar <- c("TIPI2", "TIPI4", "TIPI6", "TIPI8", "TIPI10")

# Codificación inversa
df <- df %>%
  mutate(across(all_of(columnas_a_codificar), ~if_else(. %in% c(1, 2, 3, 4, 5, 6, 7), recode(., `7` = 1, `6` = 2, `5` = 3, `4` = 4, `3` = 5, `2` = 6, `1` = 7), .)))



```


Ahora vamos a calcular las sumas de cada rasgo de Personalidad: Extroversion,	Agreeableness,	Conscientiousness,	Emotional Stability,	Openness, y sus respectivos valores porcentuales (máximo es 7)

```{r Big Five ranks}

df$Extraversion <- (df$TIPI1 + df$TIPI6) / 2
df$Extraversion_perc <- df$Extraversion / 7
df$Agreeableness <- (df$TIPI2 + df$TIPI7) / 2
df$Agreeableness_perc <- df$Agreeableness / 7
df$Conscientiousness <- (df$TIPI3 + df$TIPI8) / 2
df$Conscientiousness_perc <- df$Conscientiousness / 7
df$EmotionalStability <- (df$TIPI4 + df$TIPI9) / 2
df$EmotionalStability_perc <- df$EmotionalStability / 7
df$Openness <- (df$TIPI5 + df$TIPI10) / 2
df$Openness_perc <- df$Openness / 7
head(df[, c("Extraversion", "Extraversion_perc", "Agreeableness", "Agreeableness_perc", "Conscientiousness", "Conscientiousness_perc", "EmotionalStability", "EmotionalStability_perc", "Openness", "Openness_perc")])
```




Ademas vamos a filtrar aquellos valores que en VCL6, VCL9 y VCL12 tengan como respuesta un "1" ya que son preguntas-señuelo que nos indican que la persona no estaba concentrada, o contestó al azar, o no podemos asegurar que haya comprendido correctamente las consignas. Lo mismo haremos en los casos donde todas las preguntas VCL sean 0, ya que también indicaría que esos resultados no son confiables. 


```{r Filtrado}
library(ggplot2)

# Calculamos la proporción de datos que vamos a eliminar
prop_condicion <- df %>%
  filter(VCL6 == 1 | VCL9 == 1 | VCL12 == 1 | (VCL1 == 0 & VCL2 == 0 & VCL3 == 0 & VCL4 == 0 & VCL5 == 0 & VCL6 == 0 & VCL7 == 0 & VCL8 == 0 & VCL9 == 0 & VCL10 == 0 & VCL11 == 0 & VCL12 == 0)) %>%
  nrow() / nrow(df)




# Filtrar las filas que cumplen la condición y actualizar el dataframe
df_filtrado <- df %>%
  filter(!(VCL6 == 1 | VCL9 == 1 | VCL12 == 1 | (VCL1 == 0 & VCL2 == 0 & VCL3 == 0 & VCL4 == 0 & VCL5 == 0 & VCL6 == 0 & VCL7 == 0 & VCL8 == 0 & VCL9 == 0 & VCL10 == 0 & VCL11 == 0 & VCL12 == 0)))

# Muestra los primeros registros del dataframe filtrado
head(df_filtrado)


```


Asimismo, quitaremos todos aquellos registros donde todas las respuestas tengan el mismo valor.


```{r Limpiando datos}

filas_con_mismo_valor <- apply(df_filtrado[, grep("^Q\\d+A$", colnames(df_filtrado))], 1, function(x) length(unique(x)) == 1)

# Filtrar el dataframe
df_filtrado <- df_filtrado[!filas_con_mismo_valor, ]

cat("Número de filas después de limpiar:", nrow(df_filtrado), "\n")


```
### Duracion

Estas medidas nos permiten observar que hay datos máximos que llaman la atención. 
Para asegurar que los datos sean confiables, vamos a filtrar aquellos que sean outliers en tiempo (testelapse, surveyelapse), y también aquellos donde todas las respuestas hayan sido con el mismo puntaje (todas 4, o todas 1, o todas 2, o todas 3, etc)

```{r Verificar tiempos}

columnas_duracion <- c("testelapse", "sum_T_elapsed", "surveyelapse")

df_filtrado$sum_T_elapsed <- rowSums(df_filtrado[, grep("^Q\\d+E$", colnames(df_filtrado))])
df_filtrado$sum_T_elapsed <- df_filtrado$sum_T_elapsed / 1000
head(df_filtrado[,columnas_duracion])
summary(df_filtrado[,columnas_duracion])
```

Dado que testelapse y surveyelapse corresponden a el tiempo en segundos que se tardó en responde todo el test, tenemos que considerar que siendo 42 preguntas del test no podemos confiar demasiado en aquellos registros que hayan tardado menos de 1 minuto y más de 40 minutos 

```{r Eliminamos absurdos}

df_filtrado <- df_filtrado %>%
  filter(testelapse >= 60, testelapse <= 2400, surveyelapse <= 2400, surveyelapse >=60)

```


Habiendo limpiado los absurdos, vamos a verificar los outliers.

```{r Outliers de tiempo}

iqr_testelapse <- IQR(df_filtrado$testelapse)
iqr_surveyelapse <- IQR(df_filtrado$surveyelapse)

# Definir los límites para identificar outliers
limite_superior_testelapse <- quantile(df_filtrado$testelapse)[4] + 1.5 * iqr_testelapse
limite_inferior_testelapse <- quantile(df_filtrado$testelapse)[2] - 1.5 * iqr_testelapse

limite_superior_surveyelapse <- quantile(df_filtrado$surveyelapse)[4] + 1.5 * iqr_surveyelapse
limite_inferior_surveyelapse <- quantile(df_filtrado$surveyelapse)[2] - 1.5 * iqr_surveyelapse

# Identificar outliers en testelapse y surveyelapse
outliers_testelapse <- df_filtrado$testelapse > limite_superior_testelapse | df_filtrado$testelapse < limite_inferior_testelapse
outliers_surveyelapse <- df_filtrado$surveyelapse > limite_superior_surveyelapse | df_filtrado$surveyelapse < limite_inferior_surveyelapse

# Contar y mostrar los outliers
cat("Número de outliers en testelapse:", sum(outliers_testelapse), "\n")
cat("Número de outliers en surveyelapse:", sum(outliers_surveyelapse), "\n")

# Crear un boxplot para testelapse con outliers marcados
ggplot(df_filtrado, aes(x = factor(1), y = testelapse)) +
  geom_boxplot(outlier.shape = 16, outlier.colour = "red") +
  labs(title = "Boxplot de testelapse con outliers marcados",
       x = "",
       y = "testelapse") +
  theme_minimal()

# Crear un boxplot para surveyelapse con outliers marcados
ggplot(df_filtrado, aes(x = factor(1), y = surveyelapse)) +
  geom_boxplot(outlier.shape = 16, outlier.colour = "red") +
  labs(title = "Boxplot de surveyelapse con outliers marcados",
       x = "",
       y = "surveyelapse") +
  theme_minimal()



```

Ahora procedemos a filtrar los outliers y observar los boxplots luego de quitar outliers.

```{r Eliminamos outliers de tiempo}

df_filtrado <- df_filtrado %>%
  filter(testelapse >= limite_inferior_testelapse, testelapse <= limite_superior_testelapse,
         surveyelapse >= limite_inferior_surveyelapse, surveyelapse <= limite_superior_surveyelapse)

# Verificar el nuevo tamaño del dataframe después de la eliminación de outliers
cat("Número de filas después de eliminar outliers:", nrow(df_filtrado), "\n")

# Crear un boxplot para testelapse con outliers marcados
ggplot(df_filtrado, aes(x = factor(1), y = testelapse)) +
  geom_boxplot(outlier.shape = 16, outlier.colour = "red") +
  labs(title = "Boxplot de testelapse con outliers marcados",
       x = "",
       y = "testelapse") +
  theme_minimal()

# Crear un boxplot para surveyelapse con outliers marcados
ggplot(df_filtrado, aes(x = factor(1), y = surveyelapse)) +
  geom_boxplot(outlier.shape = 16, outlier.colour = "red") +
  labs(title = "Boxplot de surveyelapse con outliers marcados",
       x = "",
       y = "surveyelapse") +
  theme_minimal()

ggplot(df_filtrado, aes(x = testelapse)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(title = "Densidad de testelapse sin outliers",
       x = "testelapse",
       y = "Densidad") +
  theme_minimal()

ggplot(df_filtrado, aes(x = surveyelapse)) +
  geom_density(fill = "orange", alpha = 0.5) +
  labs(title = "Densidad de surveyelapse sin outliers",
       x = "testelapse",
       y = "Densidad") +
  theme_minimal()


```






## EDA - Analisis Exploratorio


### Variables Target

Verificaremos las variables que seran las target: Depresion, Ansiedad y Stress

Se puede observar que el Stress tiene una distribución que se asemeja un poco a una normal a primera vista, mientras que la Depresión tiene una distribución considerablemente más uniforme, y la Ansiedad se asemeja un poco a una Chi-cuadrado. 

Veamos ahora nuestras variables de Personalidad:

```{r EDA 0_1 }

# Definir colores para cada variable
color_depresion <- "green"
color_ansiedad <- "orange"
color_stress <- "purple"
colores_depresion <- c("green", "yellow", "orange", "red")

ggplot(df_filtrado, aes(x = factor(1), y = Depresion)) +
  geom_boxplot(fill = color_depresion, color = "black") +
  labs(title = "Boxplot de Depresion",
       x = "",
       y = "Depresion") +
  theme_minimal()

# Crear el gráfico utilizando ggplot2 con un margen más amplio en el eje x
ggplot(df_filtrado, aes(x = Depresion, fill = factor(Depresion_cat))) +
  geom_histogram(color = "black", binwidth = 1, position = "identity") +
  
  # Personalizar colores
  scale_fill_manual(values = colores_depresion) +
  
  labs(title = "Histograma de Depresion por Niveles",
       x = "Depresion",
       y = "Frecuencia") +
  
  theme_minimal()


ggplot(df_filtrado, aes(x = Ansiedad, fill = factor(Ansiedad_cat))) +
  geom_histogram(color = "black", binwidth = 1, position = "identity") +
  
  # Personalizar colores
  scale_fill_manual(values = colores_depresion) +
  
  labs(title = "Histograma de Ansiedad por Niveles",
       x = "Ansiedad",
       y = "Frecuencia") +
  
  theme_minimal()


ggplot(df_filtrado, aes(x = Stress, fill = factor(Stress_cat))) +
  geom_histogram(color = "black", binwidth = 1, position = "identity") +
  
  # Personalizar colores
  scale_fill_manual(values = colores_depresion) +
  
  labs(title = "Histograma de Stress por Niveles",
       x = "Stress",
       y = "Frecuencia") +
  
  theme_minimal()


```



```{r EDA 1}

columnas_personales <- c("education", "urban", "gender", "engnat", "age", "hand", "religion", "orientation", "race", "voted", "married", "familysize")

columnas_duracion <- c("testelapse", "surveyelapse")

columnas_interesantes <- c("Depresion","Ansiedad","Stress",  "Extraversion", "Agreeableness",  "Conscientiousness", "EmotionalStability", "Openness") 

cat("Summary interesantes: ")
summary(df_filtrado[, columnas_interesantes])
cat("Summary duracion: ")
summary(df_filtrado[,columnas_duracion])
cat("Summary personales: ")
summary(df_filtrado[,columnas_personales])

```


### Variables de interés predictivo

Vamos a analizar aquí nuestras variables de interés predictivos, es decir, las 5 dimensiones o rasgos de personalidad. 


```{r Big Five}

# Definir colores para cada variable de personalidad
color_extraversion <- "skyblue"
color_agreeableness <- "lightcoral"
color_conscientiousness <- "lightgreen"
color_emotional_stability <- "gold"
color_openness <- "mediumpurple"

# Crear histograma y boxplot para la variable de Extraversion
ggplot(df_filtrado, aes(x = Extraversion)) +
  geom_histogram(fill = color_extraversion, color = "black", bins = 14) +
  labs(title = "Histograma de Extraversion",
       x = "Extraversion",
       y = "Frecuencia") +
  theme_minimal()

ggplot(df_filtrado, aes(x = factor(1), y = Extraversion)) +
  geom_boxplot(fill = color_extraversion, color = "black") +
  labs(title = "Boxplot de Extraversion",
       x = "",
       y = "Extraversion") +
  theme_minimal()

# Crear histograma y boxplot para la variable de Agreeableness
ggplot(df_filtrado, aes(x = Agreeableness)) +
  geom_histogram(fill = color_agreeableness, color = "black", bins = 14) +
  labs(title = "Histograma de Agreeableness",
       x = "Agreeableness",
       y = "Frecuencia") +
  theme_minimal()

ggplot(df_filtrado, aes(x = factor(1), y = Agreeableness)) +
  geom_boxplot(fill = color_agreeableness, color = "black") +
  labs(title = "Boxplot de Agreeableness",
       x = "",
       y = "Agreeableness") +
  theme_minimal()

# Crear histograma y boxplot para la variable de Conscientiousness
ggplot(df_filtrado, aes(x = Conscientiousness)) +
  geom_histogram(fill = color_conscientiousness, color = "black", bins = 14) +
  labs(title = "Histograma de Conscientiousness",
       x = "Conscientiousness",
       y = "Frecuencia") +
  theme_minimal()

ggplot(df_filtrado, aes(x = factor(1), y = Conscientiousness)) +
  geom_boxplot(fill = color_conscientiousness, color = "black") +
  labs(title = "Boxplot de Conscientiousness",
       x = "",
       y = "Conscientiousness") +
  theme_minimal()

# Crear histograma y boxplot para la variable de Emotional Stability
ggplot(df_filtrado, aes(x = EmotionalStability)) +
  geom_histogram(fill = color_emotional_stability, color = "black", bins = 14) +
  labs(title = "Histograma de Emotional Stability",
       x = "Emotional Stability",
       y = "Frecuencia") +
  theme_minimal()

ggplot(df_filtrado, aes(x = factor(1), y = EmotionalStability)) +
  geom_boxplot(fill = color_emotional_stability, color = "black") +
  labs(title = "Boxplot de Emotional Stability",
       x = "",
       y = "Emotional Stability") +
  theme_minimal()

# Crear histograma y boxplot para la variable de Openness
ggplot(df_filtrado, aes(x = Openness)) +
  geom_histogram(fill = color_openness, color = "black", bins = 14) +
  labs(title = "Histograma de Openness",
       x = "Openness",
       y = "Frecuencia") +
  theme_minimal()

ggplot(df_filtrado, aes(x = factor(1), y = Openness)) +
  geom_boxplot(fill = color_openness, color = "black") +
  labs(title = "Boxplot de Openness",
       x = "",
       y = "Openness") +
  theme_minimal()
```



### Correlaciones 


```{r Correlaciones}
library(corrplot)

# Seleccionar las variables de interés
variables_interes <- c("Depresion", "Ansiedad", "Stress", "Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness")

# Crear una submatriz con las variables seleccionadas
matriz_correlacion <- df_filtrado[, variables_interes]

# Eliminar filas y columnas con valores NA
matriz_correlacion <- matriz_correlacion[complete.cases(matriz_correlacion), ]

# Calcular la matriz de correlación
matriz_correlacion <- cor(matriz_correlacion)

# Visualizar la matriz de correlación usando corrplot
corrplot(matriz_correlacion, method = "number", type = "upper", order = "hclust", tl.col = "black", tl.srt = 45, addCoef.col = "black", number.cex = 0.7)

```

Se observa que la estabilidad emocional tiene una correlacion negativa bastante alta con nuestras tres variables target, mayormente con Estrés. El resto de los rasgos de personalidad tienen todos correlacion negativa pero relativamente baja con nuestras variables target. Analicemos ahora en función de datos personales. 




## Modelo CART

### Preparación adicional de datos


Vamos a factorizar columnas que usaremos más adelante, que corresponden a las preguntas de índole personal y demográfica.

```{r Factorizacion}

columnas_personales <- c("education", "urban", "gender", "engnat", "hand", "religion", "orientation", "race", "voted", "married", "familysize")

# Filtrar filas con valores NA en las columnas de interés
df_filtrado <- df_filtrado[complete.cases(df_filtrado[columnas_personales]), ]

# Identificar y factorizar solo las columnas de tipo "character" o "factor"
df_filtrado[columnas_personales] <- sapply(df_filtrado[columnas_personales], function(x) {
  if(is.character(x) || is.factor(x)) {
    return(as.factor(x))
  } else {
    return(x)
  }
})

# Verificar el resultado
str(df_filtrado[columnas_personales])



```

### Preparamos nuestro train y test. 

Vamos a comenzar factorizando nuestras variables categóricas Depresion_cat, Ansiedad_cat, y Stress_cat

```{r Factorizamos categorias}

library(dplyr)
library(forcats)

# Columnas a codificar
columnas_a_codificar <- c("Depresion_cat", "Ansiedad_cat", "Stress_cat")

# Función para codificar las categorías
codificar_categoria <- function(x) {
  recode(x,
    "Normal" = 0,
    "Leve" = 1,
    "Moderado" = 2,
    "Severo" = 3,
    .default = as.numeric(as.character(x))
  )
}

# Aplica la codificación a cada columna y crea nuevas columnas
df_filtrado <- df_filtrado %>%
  mutate(
    Depresion_cat_f = codificar_categoria(Depresion_cat),
    Ansiedad_cat_f = codificar_categoria(Ansiedad_cat),
    Stress_cat_f = codificar_categoria(Stress_cat)
  )



```
Verificamos las proporciones de la severidad para Depresión.


```{r Proporciones}

prop_target <- prop.table(table(df_filtrado$Depresion_cat))
prop_target

```


```{r Modelo CART}
library(caret)
set.seed(17)
# Agregar una columna de ID
df_filtrado$ID <- seq_len(nrow(df_filtrado))

# Definir las variables predictoras
variables_predictoras <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness", "education", "urban", "gender", "engnat", "hand", "religion", "orientation", "race", "voted", "married", "familysize")

# Definir las variables objetivo
variables_objetivo <- c("Depresion_cat", "Ansiedad_cat", "Stress_cat")
df_modelo <- df_filtrado[, c(variables_predictoras, variables_objetivo, "ID")]

# Dividir en train y test
indice_entrenamiento <- createDataPartition(df_modelo$Depresion, p = 0.7, list = FALSE)

#Train
df_entrenamiento <- df_modelo[indice_entrenamiento, ]

#Test
df_prueba <- df_modelo[-indice_entrenamiento, ]


```


### Modelo para Depresion


```{r Depresion}
library(rpart.plot)
# Crear una fórmula para el modelo


variables_predictoras_depresion <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness",  "Depresion_cat")

variables_predictoras_ansiedad <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness", "Ansiedad_cat")

variables_predictoras_stress <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness", "Stress_cat")


df_entrenamiento_depresion <- df_entrenamiento[variables_predictoras_depresion]

df_entrenamiento_stress <- df_entrenamiento[variables_predictoras_stress]

df_entrenamiento_ansiedad <- df_entrenamiento[variables_predictoras_ansiedad]

#formula <- as.formula(paste('Depresion', " ~ ."))

# Entrenar el modelo en el conjunto de entrenamiento
modelo_cart_depresion <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion, method = 'class')

# Resumen del modelo
print(paste("Resumen del modelo para", 'Depresion'))
print(summary(modelo_cart_depresion))

# Visualizar el árbol de decisión 
rpart.plot(modelo_cart_depresion)



```

Vemos que, sin pasarle ningún hiperparámetro, el árbol decide únicamente en base al valor que tenga una persona en Estabilidad Emocional, y no logra clasificar Leve ni Moderado

Probemos ahora un segundo modelo agregando algunos hiperparámetros:

```{r modelo minbucket maxdepth}

# Fit
modelo_cart_depresion_md <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion, method = "class", control = rpart.control(maxdepth = 10))

#Resumen del modelo
#print(paste("Resumen del modelo para", 'Depresion'))
#print(head(summary(modelo_cart_depresion_md)))

#Imprimimos el arbol
rpart.plot(modelo_cart_depresion_md)


#Fit 2
modelo_cart_depresion_mb <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion, method = "class", control = rpart.control(minbucket = 2))

#Resumen del modelo
#print(paste("Resumen del modelo para", 'Depresion'))
#print(head(summary(modelo_cart_depresion_mb)))



```
```{r plot mb}

#Imprimimos el arbol
rpart.plot(modelo_cart_depresion_mb)
```

Vemos que con maxdepth y minbucket el árbol no cambia. Veamos qué pasa si modificamos la complejidad.


#### Variando complejidad



```{r modelo complejidad}

# Fit
modelo_cart_depresion_cp <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion, method = "class", control = rpart.control(cp = 0.002))

#Resumen del modelo
#print(paste("Resumen del modelo para", 'Depresion'))
#print(head(summary(modelo_cart_depresion_cp)))

#Imprimimos el arbol
rpart.plot(modelo_cart_depresion_cp)


```

Vemos que aunque le dejemos crecer en complejidad,  sigue prediciendo únicamente dos de los 4 casos que tenemos, pero comienza a utilizar algunas nuevas categorias para la predicción.



Veamos cuándo aparece nuestra nueva clase en las predicciones.

```{r Clases}

#Fit
modelo_cart_depresion_cp <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion, method = "class", control = rpart.control(cp = 0.0004))

#Resumen
#print(paste("Resumen del modelo para", 'Depresion'))
#print(head(summary(modelo_cart_depresion_cp)))

#Grafico
rpart.plot(modelo_cart_depresion_cp)

plotcp(modelo_cart_depresion_cp)


```

Aquí vemos que con un cp = 0.0004 aparecen nuevas clases, pero tenemos muchos más nodos terminales y un árbol considerablemente más complejo que el anterior, donde sacrificamos explicabilidad. 
Si nos fijamos en el error estimado de generalización en base a CP, parecería que a partir de cp=0.0042 los valores de error son muy similares, entonces podemos considerar quedarnos con el árbol más chico de ese rango que sería un árbol de tamaño 7 y cp= 0.0042 

```{r Arbol mejor - mas chico}

modelo_cart_depresion_cp_min <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion, method = "class", control = rpart.control(cp = 0.0042))

#Resumen
#print(paste("Resumen del modelo para", 'Depresion'))
#print(head(summary(modelo_cart_depresion_cp)))

#Grafico
rpart.plot(modelo_cart_depresion_cp_min)

```

Veamos entonces qué variables son las más importantes en este modelo.


```{r Feature importance }

importancia_variables <- data.frame(variable = names(modelo_cart_depresion_cp_min$variable.importance),
                                     importancia = modelo_cart_depresion_cp_min$variable.importance)

#Ordenamos importancia
importancia_variables <- importancia_variables[order(-importancia_variables$importancia), ]

#Grafico de barras
barplot(importancia_variables$importancia, names.arg = importancia_variables$variable, 
        col = "orange", main = "Importancia de Variables", 
        xlab = "Variables", ylab = "Importancia", cex.names = 0.60)


```

Podemos ver que la variable más importante es EmotionalStability, le sigue Conscientiousness y Extraversion. Esto tiene sentido ya que son las variables que aparecieron primero en los splits del arbol. 

¿Qué pasa si agregamos más variables?


#### Modelo con más variables

```{r Mas variables}
variables_predictoras_mas <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness", "education", "urban", "gender", "engnat", "hand", "religion", "orientation", "race", "voted", "married", "familysize", "Depresion_cat")


df_entrenamiento_depresion_mas <- df_entrenamiento[variables_predictoras_mas]

#Fit
modelo_cart_depresion_cp_mas <- rpart(formula = Depresion_cat ~. , data = df_entrenamiento_depresion_mas, method = "class", control = rpart.control(cp = 0.00039))

#print(paste("Resumen del modelo para", 'Depresion'))
#print(summary(modelo_cart_depresion_cp_mas))

#Grafico arbol
rpart.plot(modelo_cart_depresion_cp_mas)

#Importancia
importancia_variables_mas <- data.frame(variable = names(modelo_cart_depresion_cp_mas$variable.importance),
                                     importancia = modelo_cart_depresion_cp_mas$variable.importance)

importancia_variables_mas <- importancia_variables_mas[order(-importancia_variables_mas$importancia), ]

barplot(importancia_variables_mas$importancia,  
        col = "orange", main = "Importancia de Variables", 
        xlab = "Variables", ylab = "Importancia") 

#Acomodamos nombres
axis(1, at = seq_along(importancia_variables_mas$variable),
     labels = importancia_variables_mas$variable, las = 2, cex.names= 0.4)

```

Con esto podemos ver que nuestras variables más importantes siguen siendo las de personalidad, mientras que las variables agregadas tienen muy poca importancia. Podemos verificar en qué grado usa cada variable en los splits. 

```{r Variables usadas}
tabla_variables <- as.data.frame(modelo_cart_depresion_cp_mas$frame$var[modelo_cart_depresion_cp_mas$frame$var != "<leaf>"])
names(tabla_variables) <- c("variable")
tabla_variables %>%
  group_by(variable) %>%
  summarise(n = n()) %>%
  mutate(freq = round(n / sum(n), 2)) %>%
  arrange(-n)

```

Efectivamente podemos ver que las variables de personalidad son las más usadas por nuestro modelo para poder predecir, y luego aparecen el tamaño del grupo familiar, la orientación sexual, el nivel educativo alcanzado, entre otras, pero con mucha menos frecuencia.


#### Poda del árbol

Cuando tenemos árboles que son complejos tenemos mayor posibilidad de overfitear. Para esto, podemos realizar poda del árbol, que consiste en eliminar ramas (nodos y hojas) para reducir su complejidad. Para nuestro caso, se eliminan las ramas o sub-árboles que no traen diferencias significativas, es decir que menor reducción de impureza proporcionan. 

Si bien la poda puede ser Pre-Pruning o Post-Pruning, en nuestro caso haremos Post-Pruning lo que implica partir de un árbol complejo y luego podarlo. 


```{r Poda del arbol}

modelo_cart_depresion_cp_mas_pruned <- prune(modelo_cart_depresion_cp_mas, cp = 0.00195)

#print(summary(modelo_cart_depresion_cp_mas_pruned))

rpart.plot(modelo_cart_depresion_cp_mas_pruned)


tabla_variables_pruned <- as.data.frame(modelo_cart_depresion_cp_mas_pruned$frame$var[modelo_cart_depresion_cp_mas_pruned$frame$var != "<leaf>"])
names(tabla_variables_pruned) <- c("variable")
tabla_variables %>%
  group_by(variable) %>%
  summarise(n = n()) %>%
  mutate(freq = round(n / sum(n), 2)) %>%
  arrange(-n)
```

De esta manera obtenemos un árbol podado a una complejidad 0.00195 






### Métricas y comparación con otros modelos 

Vamos a generar modelos de Naive Bayes y Regresion Logistica Multinomial 

```{r NB y SVM}

naive_bay <- e1071::naiveBayes(Depresion_cat ~ ., data = df_entrenamiento_depresion_mas)

modelo_rlm <- nnet::multinom(Depresion_cat ~ ., data = df_entrenamiento_depresion_mas)
  
```

```{r  Metricas}
library(pROC)
#Definimos una funcion para calcular las métriacs

calcular_metricas <- function(modelo, datos_prueba){
  
  predicciones <- predict(modelo, newdata = datos_prueba, type = "class")
  matriz_confusion <- caret::confusionMatrix(predicciones, datos_prueba$Depresion_cat)$table
  

  precision <- sum(diag(matriz_confusion)) / sum(matriz_confusion)
  sensibilidad <- matriz_confusion[2,2] / sum(matriz_confusion[2,])
  especificidad <- matriz_confusion[1,1] / sum(matriz_confusion[1,])
  f1_score <- 2* (sensibilidad * precision) / (precision + sensibilidad)
  
  # Obtener el nombre del modelo
  nombre_modelo <- deparse(substitute(modelo))
  
  # Imprimir la matriz de confusión con el nombre del modelo
  cat("Matriz de confusión para", nombre_modelo, ":\n")
  print(matriz_confusion)
 
  
  
  resultados <- data.frame(
    Modelo = deparse(substitute(modelo)),
    Precision = precision,
    Sensibilidad = sensibilidad,
    Especificidad = especificidad,
    F1_Score = f1_score
  )
  return(resultados)  
}

df_prueba_depresion_mas <- df_prueba[, variables_predictoras_mas]
df_prueba_depresion_mas$Depresion_cat <- as.factor(df_prueba_depresion_mas$Depresion_cat
                                                   )
resultados_cart <- calcular_metricas(modelo_cart_depresion_cp_mas, df_prueba_depresion_mas)

resultados_nb <- calcular_metricas(naive_bay, df_prueba_depresion_mas)
resultados_rlm <- calcular_metricas(modelo_rlm, df_prueba_depresion_mas)
resultados_cart_pruned <- calcular_metricas(modelo_cart_depresion_cp_mas_pruned, df_prueba_depresion_mas)

tabla_resultados <- rbind(resultados_cart, resultados_cart_pruned, resultados_nb, resultados_rlm)
tabla_resultados


```

Con esto podemos ver algunas cosas:

En primer lugar, ningun modelo es bueno en términos prácticos, ya que estamos hablando de una precisión menor al 60%. Además, tenemos 3 modelos que no logran predecir todos los casos. Dos de ellos solo predicen 2 de las clases (Normal y Severo), 1 de ellos predice también sobre Moderado, y solo 1, el árbol sin cortar, logra predecir todas las clases, aunque con poca precision. 



### Apéndice: (Modelos Ansiedad y Estrés)

A continuación dejamos la aplicación para modelos de Ansiedad y Estrés. En este caso, vamos a hacerlo directamente con todas las variables (rasgos de personalidad y datos personales)




#### Ansiedad


```{r Modelo Ansiedad}

variables_predictoras_ansiedad <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness", "education", "urban", "gender", "engnat", "hand", "religion", "orientation", "race", "voted", "married", "familysize", "Ansiedad_cat")


df_entrenamiento_ansiedad <- df_entrenamiento[variables_predictoras_ansiedad]

#Fit
modelo_cart_ansiedad <- rpart(formula = Ansiedad_cat ~. , data = df_entrenamiento_ansiedad, method = "class", control = rpart.control(cp = 0.00039))

#print(paste("Resumen del modelo para", 'Depresion'))
#print(summary(modelo_cart_depresion_cp_mas))

#Grafico arbol
rpart.plot(modelo_cart_ansiedad)

#Importancia
importancia_variables_ansiedad<- data.frame(variable = names(modelo_cart_ansiedad$variable.importance),
                                     importancia = modelo_cart_ansiedad$variable.importance)

importancia_variables_ansiedad <- importancia_variables_ansiedad[order(-importancia_variables_ansiedad$importancia), ]

barplot(importancia_variables_ansiedad$importancia,  
        col = "orange", main = "Importancia de Variables", 
        xlab = "Variables", ylab = "Importancia") 

#Acomodamos nombres
axis(1, at = seq_along(importancia_variables_ansiedad$variable),
     labels = importancia_variables_ansiedad$variable, las = 2, cex.names= 0.4)


```

En principio armamos un árbol saturado para luego podarlo. Pero es interesante que entre las variables importantes, si bien Estabilidad Emocional sigue siendo definitivamente la más importante, aparece la variable de Married en tercer lugar por encima de otros tres rasgos de personalidad. 


```{r Uso de variables ansiedad}

tabla_variables_ansiedad <- as.data.frame(modelo_cart_ansiedad$frame$var[modelo_cart_ansiedad$frame$var != "<leaf>"])
names(tabla_variables_ansiedad) <- c("variable")
tabla_variables_ansiedad %>%
  group_by(variable) %>%
  summarise(n = n()) %>%
  mutate(freq = round(n / sum(n), 2)) %>%
  arrange(-n)

```

Sin embargo, Married no parece ser una columna tan usada por el modelo, y nuevamente tenemos 4 de los 5 rasgos de personalidad en los primeros lugares. 

##### Arbol ansiedad podado

```{r Arbol ansiedad podado}

modelo_Cart_ansiedad_pruned <- prune(modelo_cart_ansiedad, cp = 0.002)

rpart.plot(modelo_Cart_ansiedad_pruned)
#Importancia
importancia_variables_ansiedad_pruned <- data.frame(variable = names(modelo_Cart_ansiedad_pruned$variable.importance),
                                     importancia = modelo_Cart_ansiedad_pruned$variable.importance)

importancia_variables_ansiedad_pruned <- importancia_variables_ansiedad_pruned[order(-importancia_variables_ansiedad_pruned$importancia), ]

barplot(importancia_variables_ansiedad_pruned$importancia,  
        col = "orange", main = "Importancia de Variables", 
        xlab = "Variables", ylab = "Importancia") 

#Acomodamos nombres
axis(1, at = seq_along(importancia_variables_ansiedad$variable),
     labels = importancia_variables_ansiedad$variable, las = 2, cex.names= 0.4)
```


El árbol resultante al podarlo hacia un cp = 0.002  resulta muy similar al que vimos anteriormente de Depresion. 





#### Stress


```{r Modelo Stress}

variables_predictoras_stress <- c("Extraversion", "Agreeableness", "Conscientiousness", "EmotionalStability", "Openness", "education", "urban", "gender", "engnat", "hand", "religion", "orientation", "race", "voted", "married", "familysize", "Stress_cat")


df_entrenamiento_stress <- df_entrenamiento[variables_predictoras_stress]

#Fit
modelo_cart_stress <- rpart(formula = Stress_cat ~. , data = df_entrenamiento_stress, method = "class", control = rpart.control(cp = 0.00039))



#Grafico arbol
rpart.plot(modelo_cart_stress)

#Importancia
importancia_variables_stress<- data.frame(variable = names(modelo_cart_stress$variable.importance),
                                     importancia = modelo_cart_stress$variable.importance)

importancia_variables_stress <- importancia_variables_stress[order(-importancia_variables_stress$importancia), ]

barplot(importancia_variables_stress$importancia,  
        col = "orange", main = "Importancia de Variables", 
        xlab = "Variables", ylab = "Importancia") 

#Acomodamos nombres
axis(1, at = seq_along(importancia_variables_stress$variable),
     labels = importancia_variables_stress$variable, las = 2, cex.names= 0.4)


```

En principio armamos un árbol saturado para luego podarlo. No se ve que haya diferencias grandes con la importancia de variables de Depresión ni Ansiedad, nuevamente las variables más fuertes parecen ser los rasgos de personalidad.  


```{r Uso de variables}

tabla_variables_stress <- as.data.frame(modelo_cart_stress$frame$var[modelo_cart_stress$frame$var != "<leaf>"])
names(tabla_variables_stress) <- c("variable")
tabla_variables_stress %>%
  group_by(variable) %>%
  summarise(n = n()) %>%
  mutate(freq = round(n / sum(n), 2)) %>%
  arrange(-n)

```

Aquí es interesante que Amabilidad y Escrupulosidad son utilizadas más veces para hacer divisiones en el árbol. 
 

##### Arbol Stress podado

```{r Arbol stress podado}

modelo_Cart_stress_pruned <- prune(modelo_cart_stress, cp = 0.002)

rpart.plot(modelo_Cart_stress_pruned)
#Importancia
importancia_variables_stress_pruned <- data.frame(variable = names(modelo_Cart_stress_pruned$variable.importance),
                                     importancia = modelo_Cart_stress_pruned$variable.importance)

importancia_variables_stress_pruned <- importancia_variables_stress_pruned[order(-importancia_variables_stress_pruned$importancia), ]

barplot(importancia_variables_stress_pruned$importancia,  
        col = "orange", main = "Importancia de Variables", 
        xlab = "Variables", ylab = "Importancia") 

#Acomodamos nombres
axis(1, at = seq_along(importancia_variables_stress_pruned$variable),
     labels = importancia_variables_stress_pruned$variable, las = 2, cex.names= 0.4)
```



Vemos que al podar el árbol a cp 0.002 directamente tenemos, para Stress, dos nodos terminales y una simple división en base a Estabilidad Emocional, por lo que nuevamente esta variable es un fuerte predictor para el caso binario. 

